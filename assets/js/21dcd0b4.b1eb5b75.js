"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[137],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>u});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=p(t),u=r,h=c["".concat(l,".").concat(u)]||c[u]||m[u]||i;return t?a.createElement(h,o(o({ref:n},d),{},{components:t})):a.createElement(h,o({ref:n},d))}));function u(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=c;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},1631:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const i={title:"Resolvers"},o=void 0,s={unversionedId:"schema/resolvers",id:"schema/resolvers",title:"Resolvers",description:"Resolvers are at the core of gql; a resolver Resolver[F, I, O] takes an I and produces an O in effect F.",source:"@site/docs/schema/resolvers.md",sourceDirName:"schema",slug:"/schema/resolvers",permalink:"/gql/docs/schema/resolvers",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/schema/resolvers.md",tags:[],version:"current",frontMatter:{title:"Resolvers"},sidebar:"docs",previous:{title:"The DSL",permalink:"/gql/docs/schema/dsl"},next:{title:"The schema",permalink:"/gql/docs/schema/"}},l={},p=[{value:"Resolvers",id:"resolvers",level:2},{value:"Lift",id:"lift",level:3},{value:"LiftF",id:"liftf",level:3},{value:"Arguments",id:"arguments",level:3},{value:"Meta",id:"meta",level:3},{value:"Errors",id:"errors",level:3},{value:"First",id:"first",level:3},{value:"Batch",id:"batch",level:3},{value:"Batch resolver syntax",id:"batch-resolver-syntax",level:4},{value:"Batchers from elsewhere",id:"batchers-from-elsewhere",level:4},{value:"Choice",id:"choice",level:3},{value:"Stream",id:"stream",level:3},{value:"Stream semantics",id:"stream-semantics",level:4},{value:"Steps",id:"steps",level:2},{value:"Additional syntax for resolvers TODO",id:"additional-syntax-for-resolvers-todo",level:2},{value:"PureResolver",id:"pureresolver",level:2},{value:"EffectResolver",id:"effectresolver",level:2},{value:"FallibleResolver",id:"fallibleresolver",level:2},{value:"BatchResolver",id:"batchresolver",level:2},{value:"Example of a database batcher",id:"example-of-a-database-batcher",level:3},{value:"Design patterns",id:"design-patterns",level:3},{value:"StreamResolver",id:"streamresolver",level:2},{value:"Stream semantics",id:"stream-semantics-1",level:3},{value:"Interesting use cases",id:"interesting-use-cases",level:3},{value:"Resolver composition",id:"resolver-composition",level:2}],d={toc:p};function m(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Resolvers are at the core of gql; a resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O]")," takes an ",(0,r.kt)("inlineCode",{parentName:"p"},"I")," and produces an ",(0,r.kt)("inlineCode",{parentName:"p"},"O")," in effect ",(0,r.kt)("inlineCode",{parentName:"p"},"F"),".\nResolvers are embedded in fields and act as continuations.\nWhen gql executes a query it first constructs a tree of continueations from your schema and the supplied GraphQL query."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"Resolver"),"s act and compose like functions with combinators such as ",(0,r.kt)("inlineCode",{parentName:"p"},"andThen")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"compose"),"."),(0,r.kt)("p",null,"Lets start off with some imports:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import gql.dsl._\nimport gql.resolver._\nimport gql.ast._\nimport cats.effect._\nimport cats.implicits._\nimport cats.data._\n")),(0,r.kt)("h2",{id:"resolvers"},"Resolvers"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"Resolver")," is a collection of high-level combinators that constructs a tree of ",(0,r.kt)("inlineCode",{parentName:"p"},"Step"),"."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"If you are familiar with the relationship between ",(0,r.kt)("inlineCode",{parentName:"p"},"fs2.Stream")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"fs2.Pull"),", then the relationship between ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Step")," should be familiar.")),(0,r.kt)("h3",{id:"lift"},"Lift"),(0,r.kt)("p",null,"The simplest ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver")," type is ",(0,r.kt)("inlineCode",{parentName:"p"},"lift")," which simply lifts a function ",(0,r.kt)("inlineCode",{parentName:"p"},"I => O")," into ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O]"),".\n",(0,r.kt)("inlineCode",{parentName:"p"},"lift"),"'s method form is ",(0,r.kt)("inlineCode",{parentName:"p"},"map"),", which for any resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O]")," produces a new resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O2]")," given a function ",(0,r.kt)("inlineCode",{parentName:"p"},"O => O2"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val r = Resolver.lift[IO, Int](_.toLong)\n// r: Resolver[IO, Int, Long] = gql.resolver.Resolver@4114dc1c\nr.map(_.toString())\n// res0: Resolver[IO, Int, String] = gql.resolver.Resolver@63e02f87\n")),(0,r.kt)("h3",{id:"liftf"},"LiftF"),(0,r.kt)("p",null,"Another simple resolver is ",(0,r.kt)("inlineCode",{parentName:"p"},"liftF")," which lifts a function ",(0,r.kt)("inlineCode",{parentName:"p"},"I => F[O]")," into ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O]"),".\n",(0,r.kt)("inlineCode",{parentName:"p"},"liftF"),"'s method form is ",(0,r.kt)("inlineCode",{parentName:"p"},"evalMap"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val r = Resolver.liftF[IO, Int](i => IO(i.toLong))\n// r: Resolver[IO, Int, Long] = gql.resolver.Resolver@3b3c5340\nr.evalMap(l => IO(l.toString()))\n// res1: Resolver[[x]IO[x], Int, String] = gql.resolver.Resolver@1a2a8ab3\n")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("inlineCode",{parentName:"p"},"liftF")," is a combination of ",(0,r.kt)("inlineCode",{parentName:"p"},"lift")," and then embedding the effect ",(0,r.kt)("inlineCode",{parentName:"p"},"F")," into resolver.\nThe implementation of ",(0,r.kt)("inlineCode",{parentName:"p"},"liftF")," is a composition of ",(0,r.kt)("inlineCode",{parentName:"p"},"Step.Alg.Lift")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Step.Alg.EmbedEffect"),".\nMost resolvers are implemented or composed on by ",(0,r.kt)("inlineCode",{parentName:"p"},"lift"),"ing a function and composing an embedding.")),(0,r.kt)("h3",{id:"arguments"},"Arguments"),(0,r.kt)("p",null,"Arguments in gql are provided through resolvers.\nA resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, A]")," can be constructed from an argument ",(0,r.kt)("inlineCode",{parentName:"p"},"Arg[A]"),", through either ",(0,r.kt)("inlineCode",{parentName:"p"},"argument")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"arg")," in method form."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val r = Resolver.argument[IO, Nothing, String](arg[String]("name"))\n// r: Resolver[IO, Nothing, String] = gql.resolver.Resolver@7db941d6\nval r2 = r.arg(arg[Int]("age"))\n// r2: Resolver[IO, Nothing, (Int, String)] = gql.resolver.Resolver@1fc7c5f1\nr2.map{ case (age, name) => s"$name is $age years old" }\n// res2: Resolver[IO, Nothing, String] = gql.resolver.Resolver@4638231a\n')),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"Arg")," also has an applicative defined for it, so multi-argument resolution can be simplified to:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val r = Resolver.argument[IO, Nothing, (String, Int)]((arg[String]("name"), arg[Int]("age")).tupled)\n// r: Resolver[IO, Nothing, (String, Int)] = gql.resolver.Resolver@809567c\nr.map{ case (age, name) => s"$name is $age years old" }\n// res3: Resolver[IO, Nothing, String] = gql.resolver.Resolver@3f09015a\n')),(0,r.kt)("h3",{id:"meta"},"Meta"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"meta")," resolver provides metadata regarding query execution, such as the position of query execution, field aliasing and the provided arguments."),(0,r.kt)("h3",{id:"errors"},"Errors"),(0,r.kt)("p",null,"Well formed errors are returned in an ",(0,r.kt)("inlineCode",{parentName:"p"},"cats.data.Ior"),".\nAn ",(0,r.kt)("inlineCode",{parentName:"p"},"Ior")," is a non-exclusive ",(0,r.kt)("inlineCode",{parentName:"p"},"Either"),"."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Ior")," datatype's left side must be ",(0,r.kt)("inlineCode",{parentName:"p"},"String")," and acts as an optional error that will be present in the query result.\ngql can return an error and a result for the same path, given that ",(0,r.kt)("inlineCode",{parentName:"p"},"Ior")," has both left and right side defined."),(0,r.kt)("p",null,"Errors are embedded into resolvers via ",(0,r.kt)("inlineCode",{parentName:"p"},"rethrow"),".\nThe extension method ",(0,r.kt)("inlineCode",{parentName:"p"},"rethrow")," is present on any resolver of type ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, Ior[String, O]]"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val r = Resolver.lift[IO, Int](i => Ior.Both("I will be in the errors :)", i))\n// r: Resolver[IO, Int, Ior.Both[String, Int]] = gql.resolver.Resolver@1e40a307\nr.rethrow\n// res4: Resolver[[A]IO[A], Int, Int] = gql.resolver.Resolver@19676326\n')),(0,r.kt)("h3",{id:"first"},"First"),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver")," also implements ",(0,r.kt)("inlineCode",{parentName:"p"},"first")," (",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, A, B] => Resolver[F, (A, C), (B, C)]"),") which is very convinient since some ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver"),"s are constant functions (they throw away their arguments/",(0,r.kt)("inlineCode",{parentName:"p"},"I"),").\nSince a ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver")," does not form a ",(0,r.kt)("inlineCode",{parentName:"p"},"Monad"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"first")," is necessary to implement non-trivial resolver compositions.\nFor instance, resolving an argument will ignore the input of the resolver, which is not always the desired outcome."),(0,r.kt)("p",null,"Lets assume we'd like to implement a resolver given a name can get a list of friends for the person with that name:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'type PersonId = Int\n\ncase class Person(id: PersonId, name: String)\n\ndef getFriends(id: PersonId, limit: Int): IO[List[Person]] = ???\n\ndef getPerson(name: String): IO[Person] = ???\n\ndef getPersonResolver = Resolver.liftF[IO, String](getPerson)\n\ndef limitResolver = Resolver.argument[IO, Person, Int](arg[Int]("limit"))\n\ngetPersonResolver andThen \n  limitResolver.first[Person].contramap[Person](p => (p, p)) andThen\n  Resolver.liftF{ case (limit, p) => getFriends(p.id, limit) }\n// res5: Resolver[[x]IO[x], String, List[Person]] = gql.resolver.Resolver@5b1f7cc0\n')),(0,r.kt)("p",null,"The above example might be a bit tough to follow, but there methods available to make such formulations less verbose."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'getPersonResolver\n  .arg(arg[Int]("limit"))\n  .evalMap{ case (limit, p) => getFriends(p.id, limit) }\n// res6: Resolver[[x]IO[x], String, List[Person]] = gql.resolver.Resolver@2c6ba528\n')),(0,r.kt)("h3",{id:"batch"},"Batch"),(0,r.kt)("p",null,"Like most other GraphQL implementations, gql also supports batching."),(0,r.kt)("p",null,"Unlike most other GraphQL implementations, gql's batching implementation features a global query planner that lets gql delay field execution until it can be paired with another field."),(0,r.kt)("p",null,"Batch declaration and usage occurs as follows:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Declare a function ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K] => F[Map[K, V]]"),"."),(0,r.kt)("li",{parentName:"ul"},"Give this function to gql and get back a ",(0,r.kt)("inlineCode",{parentName:"li"},"Resolver[F, Set[K], Map[K, V]]")," in a ",(0,r.kt)("inlineCode",{parentName:"li"},"State")," monad (for unique id generation)."),(0,r.kt)("li",{parentName:"ul"},"Use this new resolver where you want batching.")),(0,r.kt)("p",null,"And now put into practice:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"case class Person(id: Int, name: String)\n\ndef getPeopleFromDB(ids: Set[Int]): IO[List[Person]] = ???\n\nResolver.batch[IO, Int, Person]{ keys => \n  getPeopleFromDB(keys).map(_.map(x => x.id -> x).toMap)\n}\n// res7: State[gql.SchemaState[IO], Resolver[IO, Set[Int], Map[Int, Person]]] = cats.data.IndexedStateT@37a86339\n")),(0,r.kt)("p",null,"Whenever gql sees this resolver in any composition, it will look for similar resolvers during query planning."),(0,r.kt)("p",null,"Note however that the you should only declare each batch resolver variant ",(0,r.kt)("strong",{parentName:"p"},"once"),", that is, you should build your schema in ",(0,r.kt)("inlineCode",{parentName:"p"},"State"),". gql consideres different batch instantiations incompatible regardless of any type information."),(0,r.kt)("p",null,"State has ",(0,r.kt)("inlineCode",{parentName:"p"},"Monad")," (and transitively ",(0,r.kt)("inlineCode",{parentName:"p"},"Applicative"),") defined for it, so it composes well.\nHere is an example of multiple batchers:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def b1 = Resolver.batch[IO, Int, Person](_ => ???)\ndef b2 = Resolver.batch[IO, Int, String](_ => ???)\n\n(b1, b2).tupled\n// res8: State[gql.SchemaState[IO], (Resolver[IO, Set[Int], Map[Int, Person]], Resolver[IO, Set[Int], Map[Int, String]])] = cats.data.IndexedStateT@157458b9\n")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Even if your field doesn't benefit from batching, batching can still do duplicate key elimination.")),(0,r.kt)("h4",{id:"batch-resolver-syntax"},"Batch resolver syntax"),(0,r.kt)("p",null,"When a resolver in a very specific form ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, Set[K], Map[K, V]]"),", then the gql dsl provides some helper methods.\nFor instance, it is very likely that a batcher is embedded in a singular context (",(0,r.kt)("inlineCode",{parentName:"p"},"K => V"),").\nHere is a showcase of some of the helper methods:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def pb: Resolver[IO, Set[Int], Map[Int, Person]] = \n  // Stub implementation\n  Resolver.lift(_ => Map.empty)\n\n// None if a key is missing\npb.optionals[List]\n// res9: Resolver[[A]IO[A], List[Int], List[Option[Person]]] = gql.resolver.Resolver@352ddfab\n\n// Emits all values\npb.values[List]\n// res10: Resolver[[A]IO[A], List[Int], List[Person]] = gql.resolver.Resolver@441e6ec3\n\n// Every key must have an associated value\n// or else raise an error via a custom show-like typeclass\nimplicit lazy val showMissingPersonId =\n  ShowMissingKeys.showForKey[Int]("not all people could be found")\npb.force[List]\n// res11: Resolver[[A]IO[A], List[Int], List[Person]] = gql.resolver.Resolver@305b6cd2\n\n// Maybe there is one value for one key?\npb.optional\n// res12: Resolver[[A]IO[A], Int, Option[Person]] = gql.resolver.Resolver@75d4bf0\n\n// There is always one value for one key\npb.forceOne\n// res13: Resolver[[A]IO[A], Int, Person] = gql.resolver.Resolver@5c560c37\n\n// Same as force but for non-empty containers\npb.forceNE[NonEmptyList]\n// res14: Resolver[[A]IO[A], NonEmptyList[Int], NonEmptyList[Person]] = gql.resolver.Resolver@6b091908\n')),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"For larger programs, consider declaring all your batchers up-front and putting them into some type of collection:"),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"case class MyBatchers(\n  personBatcher: Resolver[IO, Set[Int], Map[Int, Person]],\n  intStringBatcher: Resolver[IO, Set[Int], Map[Int, String]]\n)\n\n(b1, b2).mapN(MyBatchers.apply)\n// res15: State[gql.SchemaState[IO], MyBatchers] = cats.data.IndexedStateT@dfd547\n")),(0,r.kt)("p",{parentName:"admonition"},"For most batchers it is likely that you eventually want to pre-compose them in various ways, for instance requsting args, which this pattern promotes.")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Sometimes you have multiple groups of fields in the same object where each group have different performance overheads."),(0,r.kt)("p",{parentName:"admonition"},"Say you had a ",(0,r.kt)("inlineCode",{parentName:"p"},"Person")," object in your database.\nThis ",(0,r.kt)("inlineCode",{parentName:"p"},"Person")," object also exists in a remote api.\nThis remote api can tell you, the friends of a ",(0,r.kt)("inlineCode",{parentName:"p"},"Person")," given the object's id and name."),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'case class PersonId(id: Int)\n\ndef pureFields = fields[IO, PersonId](\n  "id" -> lift(_.id)\n)\n\ncase class PersonDB(\n  id: PersonId, \n  name: String, \n  remoteApiId: String\n)\n\n// SELECT id, name, remote_api_id FROM person WHERE id in (...)\ndef dbBatchResolver: Resolver[IO, PersonId, PersonDB] = ???\n\ndef dbFields = fields[IO, PersonDB](\n  "name" -> lift(_.name),\n  "apiId" -> lift(_.remoteApiId)\n)\n\ncase class PersonRemoteAPI(\n  id: PersonId, \n  friends: List[PersonId]\n)\n\n// Given a PersonDB we can call the api (via a batched GET or something)\ndef personBatchResolver: Resolver[IO, PersonDB, PersonRemoteAPI] = ???\n\ndef remoteApiFields = fields[IO, PersonRemoteAPI](\n  "friends" -> lift(_.friends)\n)\n\n// Given a PersonDB object we have the following fields\ndef dbFields2: Fields[IO, PersonDB] = \n  remoteApiFields.compose(personBatchResolver) ::: dbFields\n\n// Given a PersonId we have every field\n// If "friends" is selected, gql will first run `dbBatchResolver` and then `personBatchResolver`\ndef allFields = dbFields2.compose(dbBatchResolver) ::: pureFields\n\nimplicit def person: Type[IO, PersonId] = tpeNel[IO, PersonId](\n  "Person",\n  allFields\n)\n')),(0,r.kt)("p",{parentName:"admonition"},"The general pattern for this decomposition revolves around figuring out what the most basic description of your object is.\nIn this example, every fields can (eventually through various side-effects) be resolved from just ",(0,r.kt)("inlineCode",{parentName:"p"},"PersonId"),"."),(0,r.kt)("p",{parentName:"admonition"},"Notice that even if we had many more fields, the composition overhead remains constant.")),(0,r.kt)("h4",{id:"batchers-from-elsewhere"},"Batchers from elsewhere"),(0,r.kt)("p",null,"Most batching implementations have compatible signatures and can be adapted into a gql batcher."),(0,r.kt)("p",null,"For instance, converting ",(0,r.kt)("inlineCode",{parentName:"p"},"fetch")," to gql:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import fetch._\n\ncase class PersonId(value: Int)\ncase class Person(id: PersonId, data: String)\n\nobject People extends Data[PersonId, Person] {\n  def name = "People"\n\n  def source: DataSource[IO, PersonId, Person] = ???\n}\n\nResolver\n  .batch[IO, PersonId, Person](_.toList.toNel.traverse(People.source.batch).map(_.getOrElse(Map.empty)))\n// res16: State[gql.SchemaState[IO], Resolver[IO, Set[PersonId], Map[PersonId, Person]]] = cats.data.IndexedStateT@6db00c67\n')),(0,r.kt)("h3",{id:"choice"},"Choice"),(0,r.kt)("p",null,"Resolvers also implement ",(0,r.kt)("inlineCode",{parentName:"p"},"Choice")," via ",(0,r.kt)("inlineCode",{parentName:"p"},"(Resolver[F, A, C], Resolver[F, B, D]) => Resolver[F, Either[A, B], Either[C, D]]"),".\nOn the surface, this combinator may have limited uses, but with a bit of composition we can perform tasks such as caching."),(0,r.kt)("p",null,"For instance, a combinator derived from ",(0,r.kt)("inlineCode",{parentName:"p"},"Choice")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"skippable: Resolver[F, I, O] => Resolver[F, Either[I, O], O]"),', which acts as a variant of "caching".\nIf the right side is present we skip the underlying resolver (',(0,r.kt)("inlineCode",{parentName:"p"},"Resolver[F, I, O]"),") altogether."),(0,r.kt)("p",null,"More refined variants of this combinator also exist:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'case class PersonId(id: Int)\n\ncase class Person(id: PersonId, data: String)\n\ndef getPersonForId: Resolver[IO, PersonId, Person] = ???\n\ntype CachedPerson = Either[PersonId, Person]\ndef cachedPerson = tpe[IO, CachedPerson](\n  "Person",\n  "id" -> lift(_.map(_.id).merge.id),\n  "data" -> build[IO, CachedPerson](_.skipThat(getPersonForId).map(_.data))\n)\n')),(0,r.kt)("p",null,"We can also use some of the ",(0,r.kt)("inlineCode",{parentName:"p"},"compose")," tricks from the ",(0,r.kt)("a",{parentName:"p",href:"#batch-resolver-syntax"},"batch resolver syntax section")," if we have a lot of fields that depend on ",(0,r.kt)("inlineCode",{parentName:"p"},"Person"),". "),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The query planner treats the choice branches as parallel, such that for two instances of a choice, resolvers in the two branches may be batched together.")),(0,r.kt)("h3",{id:"stream"},"Stream"),(0,r.kt)("p",null,"The stream resolver embeds an ",(0,r.kt)("inlineCode",{parentName:"p"},"fs2.Stream")," and provides the ability to emit a stream of results for a graphql subscription."),(0,r.kt)("h4",{id:"stream-semantics"},"Stream semantics"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"When one or more streams emit, the interpreter will re-evaluate the query from the position that emitted.\nThat is, only the sub-tree that changed will be re-interpreted."),(0,r.kt)("li",{parentName:"ul"},"If two streams emit and one occurs as a child of the other, the child will be ignored since it will be replaced."),(0,r.kt)("li",{parentName:"ul"},"By default, the interpreter will only respect the most-recent emitted data.\nThis means that gql assumes that your query works in absolutes, not incrementals.\nFor instance a schema designed like the following, emits incremental updates regarding likes for some object:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},"enum LikeUpdate {\n  LIKED,\n  UNLIKED\n}\n\ntype Subscription {\n  likesFor(id: ID!): LikeUpdate!\n}\n")),(0,r.kt)("p",null,"The interpreter performs a global re-interpretation of your schema, when one or more streams emit."),(0,r.kt)("h2",{id:"steps"},"Steps"),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"Step")," is the low-level algebra for a resolver, that describes a single step of evaluation for a query.\nThe variants of ",(0,r.kt)("inlineCode",{parentName:"p"},"Step")," are clearly listed in the source code. All variants of step provide orthogonal properties."),(0,r.kt)("admonition",{type:"warning"},(0,r.kt)("p",{parentName:"admonition"},"this is not up to date")),(0,r.kt)("p",null,"Resolvers are the edges that connect fields and types.\nResolvers can be composed to build simple or complex edge strucures."),(0,r.kt)("h2",{id:"additional-syntax-for-resolvers-todo"},"Additional syntax for resolvers TODO"),(0,r.kt)("h2",{id:"pureresolver"},"PureResolver"),(0,r.kt)("p",null,"The simplest resolver is the ",(0,r.kt)("inlineCode",{parentName:"p"},"PureResolver[F, I, A]"),", which simply contains a function ",(0,r.kt)("inlineCode",{parentName:"p"},"I => A"),".\nExecution statistics for a ",(0,r.kt)("inlineCode",{parentName:"p"},"PureResolver")," are not tracked."),(0,r.kt)("h2",{id:"effectresolver"},"EffectResolver"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver[F, I, A]")," is a resolver that contains a function ",(0,r.kt)("inlineCode",{parentName:"p"},"I => F[A]")," where ",(0,r.kt)("inlineCode",{parentName:"p"},"F")," is some effect type."),(0,r.kt)("h2",{id:"fallibleresolver"},"FallibleResolver"),(0,r.kt)("p",null,"Extending the ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," with a possibility of failure leads us to the ",(0,r.kt)("inlineCode",{parentName:"p"},"FallibleResolver[F, I, A]")," with the structure ",(0,r.kt)("inlineCode",{parentName:"p"},"I => F[Ior[String, A]]"),"."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," can be implemented via the ",(0,r.kt)("inlineCode",{parentName:"p"},"FallibleResolver"),", but requires a ",(0,r.kt)("inlineCode",{parentName:"p"},"Functor")," instance for ",(0,r.kt)("inlineCode",{parentName:"p"},"F"),"."),(0,r.kt)("p",{parentName:"admonition"},"Having no typeclass constraints of ",(0,r.kt)("inlineCode",{parentName:"p"},"F")," allows us to construct fields with only one implicit parameter; the type of the field.\nThis in turn allows passing the type of the field explicitly instead of caputuring it as an implicit parameter."),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import gql.dsl._\nimport gql.ast._\nimport cats.effect._\n\neff[IO, Unit, String](_ => IO("hey"))(stringScalar)\n'))),(0,r.kt)("h2",{id:"batchresolver"},"BatchResolver"),(0,r.kt)("p",null,"The batch resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver[F, I, A]")," allows the interpreter to more effeciently fetch data.\nThe resolver captures a the following steps:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"It takes ",(0,r.kt)("inlineCode",{parentName:"li"},"I")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K]")," for some ",(0,r.kt)("inlineCode",{parentName:"li"},"K")),(0,r.kt)("li",{parentName:"ul"},"Then merges the keys ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K]")," from many different resolvers into a single ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K]")),(0,r.kt)("li",{parentName:"ul"},"Then it fetches the values using a user-defined function ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K] => F[Map[K, T]]")," for some ",(0,r.kt)("inlineCode",{parentName:"li"},"T")),(0,r.kt)("li",{parentName:"ul"},"Finally it maps the values ",(0,r.kt)("inlineCode",{parentName:"li"},"Map[K, T]")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"A"))),(0,r.kt)("p",null,"The types ",(0,r.kt)("inlineCode",{parentName:"p"},"K")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"T")," are existentially quantified inside of the ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver"),".\nWhen constructing a ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver[F, I, A]")," for ",(0,r.kt)("inlineCode",{parentName:"p"},"K")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"V")," then the ",(0,r.kt)("inlineCode",{parentName:"p"},"I = Set[K]")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"A = Map[K, V]"),"."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," must be constructed globally, that is, must not be constructed ad-hoc."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," cannot directly embed ",(0,r.kt)("inlineCode",{parentName:"p"},"Set[K] => F[Map[K, T]]"),", since this would allow ambiguity.\nWhat if two ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver"),"'s were to have their keys merged, what resolver's ",(0,r.kt)("inlineCode",{parentName:"p"},"Set[K] => F[Map[K, T]]")," should be used?")),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver[F, K, T]")," is constructed as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import gql.resolver._\nimport cats.effect._\n\nval brState = BatchResolver[IO, Int, Int](keys => IO.pure(keys.map(k => k -> (k * 2)).toMap))\n")),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," monad is used to keep track of the batchers that have been created and unique id generation.\nDuring schema construction, ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," can be composed using ",(0,r.kt)("inlineCode",{parentName:"p"},"Monad"),"ic operations.\nThe ",(0,r.kt)("inlineCode",{parentName:"p"},"Schema")," companion object contains smart constructors that run the ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," monad."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"mapBoth")," and several ",(0,r.kt)("inlineCode",{parentName:"p"},"map")," variants that exists for all ",(0,r.kt)("inlineCode",{parentName:"p"},"Resolver"),"s, can be used to align the input and output types:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import gql._\nimport gql.dsl._\nimport gql.ast._\nimport cats._\nimport cats.implicits._\n\ndef batchSchema = brState.map { (br: BatchResolver[IO, Set[Int], Map[Int, Int]]) =>\n  val adjusted: Resolver[IO, Int, Option[Int]] = br\n    .contramap[Int](Set(_))\n    .map(_.values.headOption)\n\n  SchemaShape.make[IO](\n    tpe[IO, Unit](\n      "Query",\n      "field" -> field(adjusted.contramap(_ => 42))\n    )\n  )\n}\n')),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"There are more formulations of batch resolvers that can be possible, but the chosen one has the least overhead for the developer."),(0,r.kt)("p",{parentName:"admonition"},"One could let the developer declare batch resolvers in-line and explicitly name them.\nThis would impose the validation constraint that all batch resolvers with the same name must have the same function address, or else there would be ambiguity.\nReasoning with function addreses is not very intuitive, so this is not the preferred formulation.")),(0,r.kt)("p",null,"Which we can finally run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import cats.effect.unsafe.implicits.global\nimport cats.implicits._\n\ndef query = """\n  query {\n    field\n  }\n"""\n\nSchema.stateful(batchSchema)\n  .map(Compiler[IO].compile(_, query))\n  .flatMap{ case Right(Application.Query(run)) => run.map(_.asGraphQL) }\n  .unsafeRunSync()\n')),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," de-duplicates keys since it uses ",(0,r.kt)("inlineCode",{parentName:"p"},"Set")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Map"),".\nThis means that even if no function exists that effeciently fetches your data, you can still use the ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," to de-duplicates it.")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," does not maintain ordering internally, but this doesn't mean that the output values cannot maintain order."),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def br: BatchResolver[IO, Set[Int], Map[Int, String]] = ???\n\ndef orderedBr: BatchResolver[IO, List[Int], List[String]] =\n  br.contramap[List[Int]](_.toSet).mapBoth{ case (i, m) => i.map(m.apply) }\n"))),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"For more information on how the batch resolver works, check out the ",(0,r.kt)("a",{parentName:"p",href:"/gql/docs/execution/planning"},"planning section"),".")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," can also be used to fetch multiple fields of different value efficiently and lazily."),(0,r.kt)("p",{parentName:"admonition"},"Say you had a document store that had may fields, but you only wanted to fetch a few of them.\nYou also don't want the interpreter to construct a new request for each field."),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'type DocId = String\n\nfinal case class DocumentQuery(id: DocId, field: String)\nsealed trait DocumentValue\n\n// Do some groupBy id to collect all requested fields for a DocId\ndef documentResolver: BatchResolver[IO, Set[DocumentQuery], Map[DocumentQuery, DocumentValue]] = ???\n\nlazy val adjusted = documentResolver.contramap[DocumentQuery](Set(_)).mapBoth{ case (q, m) => m(q) }\n\nimplicit lazy val documentValue: Out[IO, DocumentValue] = ???\n\ndef document = tpe[IO, DocId](\n  "Document",\n  "someField" -> field(adjusted.contramap(DocumentQuery(_, "someField"))),\n  "otherField" -> field(adjusted.contramap(DocumentQuery(_, "otherField"))),\n  "anotherField" -> field(adjusted.contramap(DocumentQuery(_, "anotherField")))\n)\n'))),(0,r.kt)("h3",{id:"example-of-a-database-batcher"},"Example of a database batcher"),(0,r.kt)("p",null,"Most applications interact with a database one way or another.\nUsually databases have a way to fetch multiple rows at once, and it is usually more efficient to do so."),(0,r.kt)("p",null,"Let's define our database:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'trait DatabaseConnection[F[_]] {\n  def get(ids: Set[Int]): F[Map[Int, String]]\n}\n\nobject DatabaseConnection {\n  def apply[F[_]](implicit F: Applicative[F]) = new DatabaseConnection[F] {\n    def get(ids: Set[Int]): F[Map[Int, String]] = {\n      println(s"executing query for ids $ids")\n      F.pure(ids.map(i => i -> s"row $i").toMap)\n    }\n  }\n}\n')),(0,r.kt)("p",null,"Now we can define our schema:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'final case class Nested(key: Int)\n\ndef databaseRoot[F[_]](implicit F: Monad[F], db: DatabaseConnection[F]) =\n  BatchResolver[F, Int, String](keys => db.get(keys)).map { br =>\n    val single = \n      br.contramap[Int](Set(_))\n        .fallibleMap(x => F.pure(x.values.headOption.toRightIor("not found")))\n\n    implicit lazy val nestedType = tpe[F, Nested](\n      "Nested",\n      "nestedValue" -> field(single.contramap[Nested](_.key))\n    )\n    \n    SchemaShape.make[F](\n      tpe[F, Unit](\n        "Query",\n        "getFirstField" -> field(arg[Int]("x"))(single.contramap{ case (_, x) => x}),\n        "getSecondField" -> field(arg[Int]("y"))(single.contramap{ case (_, x) => x}),\n        "nested" -> pure(_ => Nested(42))\n      )\n    )\n  }\n')),(0,r.kt)("p",null,"And finally execute it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def databaseQuery = """\n  query {\n    getFirstField(x: 1)\n    getSecondField(y: 2)\n    nested {\n      nestedValue\n    }\n  }\n"""\n\nimplicit def db = DatabaseConnection[IO]\n\nSchema.stateful(databaseRoot[IO])\n  .map(Compiler[IO].compile(_, databaseQuery))\n  .flatMap{ case Right(Application.Query(run)) => run.map(_.asGraphQL) }\n  .unsafeRunSync()\n')),(0,r.kt)("p",null,"Notice how the huristic query planner is able to figure out that waiting till ",(0,r.kt)("inlineCode",{parentName:"p"},"nested")," is resolved and then batching is more efficient than batching the two toplevel fields first and then resolving ",(0,r.kt)("inlineCode",{parentName:"p"},"nested"),"."),(0,r.kt)("h3",{id:"design-patterns"},"Design patterns"),(0,r.kt)("p",null,"Since ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," itself is a monad, we can compose them into ",(0,r.kt)("inlineCode",{parentName:"p"},"case class"),"es for more ergonomic implementation at scale."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import cats.implicits._\n\ntrait User\ntrait UserId\n\ntrait Company\ntrait CompanyId\n\nfinal case class DomainBatchers[F[_]](\n  userBatcher: Resolver[F, Set[UserId], Map[UserId, User]],\n  companyBatcher: Resolver[F, Set[CompanyId], Map[CompanyId, Company]],\n  doubleSumBatcher: Resolver[F, Int, Int]\n)\n\n(\n  BatchResolver[IO, UserId, User](_ => ???),\n  BatchResolver[IO, CompanyId, Company](_ => ???),\n  BatchResolver[IO, Int, Int](is => IO.pure(is.map(i => i -> (i * 2)).toMap))\n    .map(_.contramap[Int](Set(_)).map[Int](_.values.toList.combineAll))\n).mapN(DomainBatchers.apply)\n")),(0,r.kt)("h2",{id:"streamresolver"},"StreamResolver"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," is a very powerful resolver type, that can perform many different tasks.\nFirst and foremost a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," can update a sub-tree of the schema via some provided stream, like signals in frp or observables."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def streamSchema = \n  SchemaShape[IO, Unit, Unit, Unit](\n    tpe[IO, Unit]("Query", "queryCannotBeEmpty" -> pure(_ => 42)),\n    subscription = tpe[IO, Unit](\n      "Subscription",\n      "stream" -> field(stream(_ => fs2.Stream(1).repeat.lift[IO].scan(0)(_ + _)))\n    ).some\n  )\n')),(0,r.kt)("h3",{id:"stream-semantics-1"},"Stream semantics"),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," that occurs as a child another ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," has some interesting implications."),(0,r.kt)("p",null,"The first time the interpreter sees a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),", it will await the first element and subscribe the rest of the stream to a background queue."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"When a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," is interpreted during a query or mutation operation, only the head element is respected.")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"Technically, a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," with one element can perform the same task as an ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," by creating a single-element stream.\nAn ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," has less resource overhead, since it is a single function compared to a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," that has some bookkeeping associated with it.")),(0,r.kt)("p",null,"When the first element arrives, the interpreter will continue interpreting the rest of the query.\nThat is, the interpreter will be blocked until the first element arrives."),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Streams may not be empty.\nIf stream terminates before at-least one element is emitted the subscription is terminated with an error.\nIf you for whatever reason wish to do this and permantently block a graphql subscription, you can always use ",(0,r.kt)("inlineCode",{parentName:"p"},"fs2.Stream.never"),".")),(0,r.kt)("admonition",{type:"danger"},(0,r.kt)("p",{parentName:"admonition"},"It is ",(0,r.kt)("strong",{parentName:"p"},"highly")," reccomended that every stream has at least one ",(0,r.kt)("strong",{parentName:"p"},"guarenteed")," element.\nThe initial evaluation of a (sub-)tree will never complete if a stream never emits, even if future updates cause a stream to become redundant.")),(0,r.kt)("p",null,"Whenever the tail of the stream emits, the interpreter will re-evaluate the sub-tree that occurs at the ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),".\nRe-evaluation forgets everything regarding the previous children, which includes ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),"s that may occur as children.\nForgotten ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),"s are gracefully cancelled."),(0,r.kt)("p",null,"Streaming is implemented in a sort of global re-evaluation loop.\nHaving global re-evaluation allows much more stable result emission and better batching possibilities."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"If the reader is faimilar with the frontend framework ",(0,r.kt)("inlineCode",{parentName:"p"},"React"),", this works much in the same way.\n",(0,r.kt)("inlineCode",{parentName:"p"},"useEffect")," is analogous to resources in ",(0,r.kt)("inlineCode",{parentName:"p"},"fs2.Stream"),", updates are batched and the interpreter diffs previous and new trees and then effeciently applies whatever changes are necessary.")),(0,r.kt)("p",null,"An alternative formulation could involve letting every ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," have it's own re-evaluation loop, but this can have unforeseen consequences.\nFor instance, the implementation of nested streams becomes ambiguous.\nDoes an inner stream cancel when the outer emits? Does this mean that a fast outer stream can end up causing an inner stream to never emit?"),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},'The interpreter only respects elements arriving in streams that are considered "active".\nThat is, if a node emits but is also about to be removed because a parent has emitted, the interpreter will ignore the child\'s emission.')),(0,r.kt)("h3",{id:"interesting-use-cases"},"Interesting use cases"),(0,r.kt)("p",null,"Since stream can embed ",(0,r.kt)("inlineCode",{parentName:"p"},"Resource"),"s, some very interesting problems can be solved with ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),"s."),(0,r.kt)("p",null,"Say we had a very slow connection to some VPN server that we wanted to fetch data from, but only if data from the VPN had been selected."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import cats.effect.implicits._\nimport scala.concurrent.duration._\n\nfinal case class VpnData(\n  content: String,\n  hash: String,\n  connectedUser: String,\n  serverId: String\n)\n\ntype Username = String\n\ntrait VpnConnection[F[_]] {\n  def getName: F[String]\n  \n  def getCreatedAge: F[Int]\n  \n  def getDataUpdates: fs2.Stream[F, VpnData]\n}\n\nobject VpnConnection {\n  // Connection aquisition is very slow\n  def apply[F[_]](userId: Username, serverId: String)(implicit F: Async[F]): Resource[F, VpnConnection[F]] = {\n    Resource.eval(F.monotonic).flatMap{ before =>\n      Resource.makeFull[F, VpnConnection[F]]{ poll =>\n        poll{\n          F.delay(println(s"Connecting to VPN for $userId ...")) >>\n          F.sleep(500.millis) >> \n          F.delay(println(s"Connected to VPN for $userId!"))\n        }.onCancel(F.delay(println(s"Connection for $userId cancelled while connecting!"))).as{\n          new VpnConnection[F] {\n            def getName = F.delay("super_secret_file")\n            \n            def getCreatedAge = F.delay(42)\n            \n            def getDataUpdates = \n              fs2.Stream(1)\n                .repeat\n                .scan(0)(_ + _)\n                .lift[F]\n                .metered(50.millis)\n                .map{ x => println(s"emitting for user $userId");x}\n                .map(i => VpnData(s"content $i", s"hash of $i", userId, serverId))\n          }\n        }\n      }(_ => F.monotonic.map{ after => \n        println(s"Disconnecting from VPN after ${(after - before).toMillis}ms for $userId ...")\n      })\n    }\n  }\n}\n')),(0,r.kt)("p",null,"We could embed the VPN connection in a stream and pass it around to types that need it."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'final case class WithVpn[F[_], A](\n  vpn: VpnConnection[F],\n  value: A\n)\n\nfinal case class VpnMetadata(subscriptionTimestamp: String)\n\ndef currentTimestamp[F[_]](implicit F: Applicative[F]): F[String] = F.pure("now!")\n\nimplicit def vpnMetadata[F[_]: Applicative] = tpe[F, WithVpn[F, VpnMetadata]](\n  "VpnMetadata",\n  "name" -> eff(_.vpn.getName),\n  "createdAge" -> eff(_.vpn.getCreatedAge),\n  "subscriptionTimestamp" -> pure(_.value.subscriptionTimestamp),\n)\n\nimplicit def vpnData[F[_]: Applicative] = tpe[F, VpnData](\n  "VpnData",\n  "content" -> pure(_.content),\n  "hash" -> pure(_.hash),\n  "connectedUser" -> pure(_.connectedUser),\n  "serverId" -> pure(_.serverId)\n)\n\nimplicit def vpn[F[_]: Applicative] = tpe[F, VpnConnection[F]](\n  "Vpn",\n  "metadata" -> eff(conn => currentTimestamp[F].map(ts => WithVpn(conn, VpnMetadata(ts)))),\n  "data" -> field(stream(_.getDataUpdates))\n)\n\ndef root[F[_]: Async] = \n  tpe[F, Username](\n    "Subscription",\n    "vpn" -> field(arg[String]("serverId"))(stream{ case (userId, serverId) => \n      fs2.Stream.resource(VpnConnection[F](userId, serverId))\n    }),\n    "me" -> pure(identity)\n  )\n')),(0,r.kt)("p",null,"We can now try querying the VPN connection through a GraphQL query:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import gql.ast._\n\ndef subscriptionQuery = """\nsubscription {\n  vpn(serverId: "secret_server") {\n    metadata {\n      name\n      createdAge\n      subscriptionTimestamp\n    }\n    data {\n      content\n      hash\n      connectedUser\n      serverId\n    }\n  }\n}\n"""\n\ndef runVPNSubscription(q: String, n: Int, subscription: Type[IO, Username] = root[IO]) = \n  Schema\n    .simple(SchemaShape[IO, Unit, Unit, Username](\n      tpe[IO, Unit]("Query", "queryCannotBeEmpty" -> pure(_ => 42)),\n      subscription = subscription.some)\n    )\n    .map(Compiler[IO].compile(_, q, subscriptionInput = IO.pure("john_doe")))\n    .flatMap{ case Right(Application.Subscription(stream)) => \n      stream.take(n).map(_.asGraphQL).compile.toList \n    }\n  \nrunVPNSubscription(subscriptionQuery, 3).unsafeRunSync()\n')),(0,r.kt)("p",null,"We can also check the performance difference of a queries that open a VPN connection versus and ones that don't:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def bench(fa: IO[_]) = \n  for {\n    before <- IO.monotonic\n    _ <- fa.timed\n    after <- IO.monotonic\n  } yield s"duration was ${(after - before).toMillis}ms"\n  \nbench(runVPNSubscription(subscriptionQuery, 10)).unsafeRunSync()\n\nbench(runVPNSubscription(subscriptionQuery, 3)).unsafeRunSync()\n\nbench(runVPNSubscription(subscriptionQuery, 1)).unsafeRunSync()\n\ndef fastQuery = """\n  subscription {\n    me\n  }\n"""\n\nbench(runVPNSubscription(fastQuery, 1)).unsafeRunSync()\n')),(0,r.kt)("p",null,"Say that the VPN connection was based on credentials that needed to be refreshed every 600 milliseconds.\nThis is also possible:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def accessToken[F[_]: Async](username: Username): fs2.Stream[F, Username] =\n  fs2.Stream(username)\n    .lift[F]\n    .repeat\n    .metered(600.millis)\n    .zipWithIndex\n    .map{ case (un, i) => s"token-$un-$i"}\n    .map{x => println(s"a new token was issued: $x");x}\n\ndef root2[F[_]: Async] = \n  tpe[F, Username](\n    "Subscription",\n    "vpn" -> field(arg[String]("serverId"))(stream{ case (userId, serverId) => \n      accessToken[F](userId).flatMap{ token =>\n        fs2.Stream.resource(VpnConnection[F](token, serverId))\n      }\n    })\n  )\n  \nrunVPNSubscription(subscriptionQuery, 13, root2[IO]).unsafeRunSync().takeRight(3)\n')),(0,r.kt)("h2",{id:"resolver-composition"},"Resolver composition"),(0,r.kt)("p",null,"Resolvers can also be composed via the ",(0,r.kt)("inlineCode",{parentName:"p"},"CompositionResolver"),".\nThis means that the output of one resolver can be used as the input of another resolver.\nThis also means that ",(0,r.kt)("inlineCode",{parentName:"p"},"Stream"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Batch")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Effect")," resolvers can be combined in any order."),(0,r.kt)("p",null,"For instance, one can efficiently fetch some list of ids, then subscribe to the data of each id and for all changed ids, efficiently fetch the changed data.\nThis can be achieved by composing ",(0,r.kt)("inlineCode",{parentName:"p"},"Batch"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Stream")," and then ",(0,r.kt)("inlineCode",{parentName:"p"},"Batch")," again."))}m.isMDXComponent=!0}}]);