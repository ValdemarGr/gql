"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[137],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>u});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),d=p(n),u=r,h=d["".concat(l,".").concat(u)]||d[u]||c[u]||i;return n?a.createElement(h,o(o({ref:t},m),{},{components:n})):a.createElement(h,o({ref:t},m))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},1631:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const i={title:"Resolvers"},o=void 0,s={unversionedId:"schema/resolvers",id:"schema/resolvers",title:"Resolvers",description:"Resolvers are where the most interest should lie, since they act as the layer between input type and next continuation.",source:"@site/docs/schema/resolvers.md",sourceDirName:"schema",slug:"/schema/resolvers",permalink:"/gql/docs/schema/resolvers",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/schema/resolvers.md",tags:[],version:"current",frontMatter:{title:"Resolvers"},sidebar:"docs",previous:{title:"The DSL",permalink:"/gql/docs/schema/dsl"},next:{title:"Context",permalink:"/gql/docs/schema/context"}},l={},p=[{value:"EffectResolver",id:"effectresolver",level:2},{value:"BatchResolver",id:"batchresolver",level:2},{value:"Design patterns",id:"design-patterns",level:3},{value:"StreamResolver",id:"streamresolver",level:2},{value:"SignalResolver",id:"signalresolver",level:2}],m={toc:p};function c(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Resolvers are where the most interest should lie, since they act as the layer between input type and next continuation.\nThe raw resolver types are as expressive as possible to allow as many use cases as possible, which can cause a lot of noise in the daily use of gql.\nTherefore the ",(0,r.kt)("inlineCode",{parentName:"p"},"dsl")," should be enough to get started and this section should act as an introduction for the curious."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The error types have been omitted from the resolver types for brevity.")),(0,r.kt)("h2",{id:"effectresolver"},"EffectResolver"),(0,r.kt)("p",null,"The simplest resolver is the effect resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver[F, I, A]")," which takes ",(0,r.kt)("inlineCode",{parentName:"p"},"I")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"F[A]"),"."),(0,r.kt)("h2",{id:"batchresolver"},"BatchResolver"),(0,r.kt)("p",null,"The batch resolver ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver[F, I, A]")," allows the interpreter to more effeciently fetch data.\nThe resolver captures a the following steps:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"It takes ",(0,r.kt)("inlineCode",{parentName:"li"},"I")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"F[Set[K]]")," for some ",(0,r.kt)("inlineCode",{parentName:"li"},"K")),(0,r.kt)("li",{parentName:"ul"},"Then merges the keys ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K]")," from many different resolvers into a single ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K]")),(0,r.kt)("li",{parentName:"ul"},"Then it fetches the values using a user-defined function ",(0,r.kt)("inlineCode",{parentName:"li"},"Set[K] => F[Map[K, T]]")," for some ",(0,r.kt)("inlineCode",{parentName:"li"},"T")),(0,r.kt)("li",{parentName:"ul"},"Finally it maps the values ",(0,r.kt)("inlineCode",{parentName:"li"},"Map[K, T]")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"F[A]"))),(0,r.kt)("p",null,"The types ",(0,r.kt)("inlineCode",{parentName:"p"},"K")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"T")," are existentially quantified; they are not visible to the user.\nThe base-case implementation for ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," has ",(0,r.kt)("inlineCode",{parentName:"p"},"K = Set[I]")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"T = Map[I, A]"),"."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The resolver will automatically construct a GraphQL error if any of the keys are missing.\nTo avoid this, you must pad all missing keys.\nFor instance, you could map all values to ",(0,r.kt)("inlineCode",{parentName:"p"},"Some")," and pad all missing values with ",(0,r.kt)("inlineCode",{parentName:"p"},"None"),".")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," must also have an implementation of ",(0,r.kt)("inlineCode",{parentName:"p"},"Set[K] => F[Map[K, T]]"),", which is constructed globally."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," cannot directly embed ",(0,r.kt)("inlineCode",{parentName:"p"},"Set[K] => F[Map[K, T]]"),", since this would allow ambiguity.\nWhat if two ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver"),"'s were to have their keys merged, what resolver's ",(0,r.kt)("inlineCode",{parentName:"p"},"Set[K] => F[Map[K, T]]")," should be used?")),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver[F, K, T]")," is constructed as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import gql.resolver._\nimport cats.effect._\n\nval brState = BatchResolver[IO, Int, Int](keys => IO.pure(keys.map(k => k -> (k * 2)).toMap))\n// brState: cats.data.package.State[gql.SchemaState[IO], BatchResolver[IO, Set[Int], Map[Int, Int]]] = cats.data.IndexedStateT@1a42265\n")),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," monad is used to keep track of the batchers that have been created and unique id generation.\nDuring schema construction, ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," can be composed using ",(0,r.kt)("inlineCode",{parentName:"p"},"Monad"),"ic operations.\nThe ",(0,r.kt)("inlineCode",{parentName:"p"},"Schema")," companion object contains smart constructors that run the ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," monad."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"map")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"contramap")," can be used to align the input and output types:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import gql._\nimport gql.dsl._\nimport cats._\n\ndef batchSchema = brState.map { (br: BatchResolver[IO, Set[Int], Map[Int, Int]]) =>\n  val adjusted: BatchResolver[IO, Int, Option[Int]] = br\n    .contramap[Int](Set(_))\n    .map { case (_, m) => m.values.headOption }\n\n  SchemaShape[IO, Unit, Unit, Unit](\n    tpe[IO, Unit](\n      "Query",\n      "field" -> field(adjusted.contramap(_ => 42))\n    ),\n    None,\n    None\n  )\n}\n')),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"There are more formulations of batch resolvers that can be possible, but the chosen one has the least overhead for the developer."),(0,r.kt)("p",{parentName:"admonition"},"One could let the developer declare batch resolvers in-line and explicitly name them.\nThis would impose the validation constraint that all batch resolvers with the same name must have the same function address, or else there would be ambiguity.\nReasoning with function addreses is not very intuitive, so this is not the preferred formulation.")),(0,r.kt)("p",null,"Which we can finally run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import cats.effect.unsafe.implicits.global\nimport cats.implicits._\n\ndef query = """\n  query {\n    field\n  }\n"""\n\nSchema.stateful(batchSchema).flatMap{ sch =>\n  sch.assemble(query, variables = Map.empty)\n    .traverse { case Executable.Query(run) => run(()).map(_.asGraphQL) }\n}.unsafeRunSync()\n// res0: Either[parser.package.ParseError, io.circe.JsonObject] = Right(\n//   value = object[data -> {\n//   "field" : 84\n// }]\n// )\n')),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," de-duplicates keys since it uses ",(0,r.kt)("inlineCode",{parentName:"p"},"Set")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Map"),".\nThis means that even if no function exists that effeciently fetches your data, you can still use the ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," to de-duplicates it.")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver")," does not maintain ordering internally, but this doesn't mean that the output values cannot maintain order."),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def br: BatchResolver[IO, Set[Int], Map[Int, String]] = ???\n\ndef orderedBr: BatchResolver[IO, List[Int], List[String]] =\n  br.contramap[List[Int]](_.toSet).map{ case (i, m) => i.map(m.apply) }\n"))),(0,r.kt)("h3",{id:"design-patterns"},"Design patterns"),(0,r.kt)("p",null,"Since ",(0,r.kt)("inlineCode",{parentName:"p"},"State")," itself is a monad, we can compose them into ",(0,r.kt)("inlineCode",{parentName:"p"},"case class"),"es for more ergonomic implementation at scale."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import cats.implicits._\n\ntrait User\ntrait UserId\n\ntrait Company\ntrait CompanyId\n\nfinal case class DomainBatchers[F[_]](\n  userBatcher: BatchResolver[F, Set[UserId], Map[UserId, User]],\n  companyBatcher: BatchResolver[F, Set[CompanyId], Map[CompanyId, Company]],\n  doubleSumBatcher: BatchResolver[F, Int, Int]\n)\n\n(\n  BatchResolver[IO, UserId, User](_ => ???),\n  BatchResolver[IO, CompanyId, Company](_ => ???),\n  BatchResolver[IO, Int, Int](is => IO.pure(is.map(i => i -> (i * 2)).toMap)).map(\n    _\n    .contramap[Int](Set(_))\n    .map[Int]{ case (_, m) => m.values.toList.combineAll }\n  )\n).mapN(DomainBatchers.apply)\n// res1: data.IndexedStateT[Eval, SchemaState[IO], SchemaState[IO], DomainBatchers[[A]IO[A]]] = cats.data.IndexedStateT@6e05ef76\n")),(0,r.kt)("h2",{id:"streamresolver"},"StreamResolver"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," is a very powerful resolver type, that can perform many different tasks.\nFirst and foremost a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," can update a sub-tree of the schema via some provided stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def streamSchema = \n  SchemaShape[IO, Unit, Unit, Unit](\n    tpe(\n      "Query",\n      "stream" -> field(stream(_ => fs2.Stream(1).repeat.lift[IO].scan(0)(_ + _)))\n    ),\n    None,\n    None\n  )\n')),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Streams must not be empty.\nIf stream terminates before at-least one element is emitted the subscription is terminated with an error.")),(0,r.kt)("admonition",{type:"danger"},(0,r.kt)("p",{parentName:"admonition"},"It is ",(0,r.kt)("strong",{parentName:"p"},"highly")," reccomended that every stream has at least one ",(0,r.kt)("strong",{parentName:"p"},"guarenteed")," element.\nThe initial evaluation of a (sub-)tree will never complete if a stream never emits, even if future updates cause the stream to be redundant.")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"Technically, a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," with one element can perform the same task as an ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," by creating a single-element stream.\nAn ",(0,r.kt)("inlineCode",{parentName:"p"},"EffectResolver")," has less resource overhead, since it is a single function compared to a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver")," that has some bookkeeping associated with it.")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"When a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamResolver"),' is interpreted during a query or mutation operation, no "background fiber" is spawned such that only the head element is respected.')),(0,r.kt)("h1",{id:"deprecated"},"Deprecated"),(0,r.kt)("h2",{id:"signalresolver"},"SignalResolver"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," is a special type of resolver that can update itself.\nA ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver[F, I, R, A]")," contains:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"A reference to a stream of ",(0,r.kt)("inlineCode",{parentName:"li"},"R")," that can be subscribed to via ",(0,r.kt)("inlineCode",{parentName:"li"},"I")," (think ",(0,r.kt)("inlineCode",{parentName:"li"},"I => Stream[R]"),")."),(0,r.kt)("li",{parentName:"ul"},"A function to get the initial value of the signal ",(0,r.kt)("inlineCode",{parentName:"li"},"I => F[R]"),"."),(0,r.kt)("li",{parentName:"ul"},"A resolver that takes ",(0,r.kt)("inlineCode",{parentName:"li"},"(I, R)")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"F[A]"),".")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"The initial value and the stream could technically have seperate resolvers.\nIf this need arises, please open an issue.")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver"),"'s property of updating, is only relevant in subscriptions.\nIn queries and mutations, the stream part of the resolver is ignored.")),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamRef")," is a reference to a stream that can be subscribed to, it is the implementation of ",(0,r.kt)("inlineCode",{parentName:"p"},"I => Stream[R]"),".\nA ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamRef")," is constructed by suppling a subscription function ",(0,r.kt)("inlineCode",{parentName:"p"},"I => Resource[F, fs2.Stream[F, O]]"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import scala.concurrent.duration._\n\nval sr = \n  StreamRef[IO, Int, Int](i => Resource.pure{\n    fs2.Stream(1).covary[IO].repeat.scan(i)(_ + _).metered(1.second)\n  })\n")),(0,r.kt)("p",null,"TODO subscription"),(0,r.kt)("p",null,"With a ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamRef"),", we can construct a ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'def signalSchema = sr.map { s =>\n  val adjusted = \n    s.contramap[(Unit, Int)]{ case (_, i) => i}\n\n  SchemaShape[IO, Unit](\n    tpe(\n      "Query",\n      "field" -> signal(arg[Int]("initial"), adjusted).pure(_ => 0).pure{ case (_, i) => i }\n    )\n  )\n}\n')),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," is id'ed much like a ",(0,r.kt)("inlineCode",{parentName:"p"},"BatchResolver"),", but with the twist that the input value to the ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamRef")," also acts as a key.\nThis means in the above example, any subscription to the same ",(0,r.kt)("inlineCode",{parentName:"p"},"i")," will share the same stream, even latecomers."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"If you need to specify both an input to your stream and a key as two seperate parameters then please open an issue.")),(0,r.kt)("p",null,"This also means that if multiple ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver"),"'s are subscribed to the same stream, then their resolvers will be evaluated in the same iteration."),(0,r.kt)("p",null,"When a ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," updates, it forgets it's entire sub-tree and resolves it again.\nThat also means that a ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," that occurs as a direct or transitive child of another ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," which updates, will have its subscription terminated.\nIf the same child ",(0,r.kt)("inlineCode",{parentName:"p"},"SignalResolver")," occurs again in the same sub-tree, it will be re-subscribed to.\nNew subscriptions are always performed before old ones are terminated, such that in the above case the stream will never be closed."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Resource")," in the ",(0,r.kt)("inlineCode",{parentName:"p"},"StreamRef")," is opened before the initial value is fetched.\nThis allows the caller to have full control over the order of operations.\nAs such, complicated delivery schemes can be implemented such as at least once, at most once or even exactly once, if your data can implement it (versioned data).")))}c.isMDXComponent=!0}}]);